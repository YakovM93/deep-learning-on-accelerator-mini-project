import torch
from torch import optim, nn
from tqdm import tqdm
import numpy as np
import os
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

def plot_tsne(model, dataloader, device):
    '''
    model - torch.nn.Module subclass. This is your encoder model
    dataloader - test dataloader to over over data for which you wish to compute projections
    device - cuda or cpu (as a string)
    '''
    model.eval()

    images_list = []
    labels_list = []
    latent_list = []

    with torch.no_grad():
        for data in dataloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)

            #approximate the latent space from data
            latent_vector = model(images)

            images_list.append(images.cpu().numpy())
            labels_list.append(labels.cpu().numpy())
            latent_list.append(latent_vector.cpu().numpy())

    images = np.concatenate(images_list, axis=0)
    labels = np.concatenate(labels_list, axis=0)
    latent_vectors = np.concatenate(latent_list, axis=0)

    # Plot TSNE for latent space
    tsne_latent = TSNE(n_components=2, random_state=0)
    latent_tsne = tsne_latent.fit_transform(latent_vectors)

    plt.figure(figsize=(8, 6))
    scatter = plt.scatter(latent_tsne[:, 0], latent_tsne[:, 1], c=labels, cmap='tab10', s=10)  # Smaller points
    plt.colorbar(scatter)
    plt.title('t-SNE of Latent Space')
    plt.savefig('latent_tsne.png')
    plt.close()

    #plot image domain tsne
    tsne_image = TSNE(n_components=2, random_state=42)
    images_flattened = images.reshape(images.shape[0], -1)
    image_tsne = tsne_image.fit_transform(images_flattened)

    plt.figure(figsize=(8, 6))
    scatter = plt.scatter(image_tsne[:, 0], image_tsne[:, 1], c=labels, cmap='tab10', s=10)
    plt.colorbar(scatter)
    plt.title('t-SNE of Image Space')
    plt.savefig('image_tsne.png')
    plt.close()


# Handle Checkpoint Saving and Loading
def save_checkpoint(model, optimizer, epoch, train_losses, val_losses, accuracies=None, filename='checkpoint.pth'):
    """
    Save model checkpoint to file

    Args:
        model: Model to save
        optimizer: Optimizer state to save
        epoch: Current epoch number
        train_losses: List of training losses
        val_losses: List of validation losses
        accuracies: List of validation accuracies (if available)
        filename: File path to save checkpoint
    """
    state = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_losses': train_losses,
        'val_losses': val_losses,
    }

    if accuracies is not None:
        state['accuracies'] = accuracies

    # Create directory if it doesn't exist
    os.makedirs(os.path.dirname(os.path.abspath(filename)), exist_ok=True)

    # Save the checkpoint
    torch.save(state, filename)
    print(f"Checkpoint saved to {filename}")

def load_checkpoint(model, optimizer, filename='checkpoint.pth'):
    """
    Load model from checkpoint file

    Args:
        model: Model to load weights into
        optimizer: Optimizer to load state into
        filename: File path to load checkpoint from

    Returns:
        epoch: Last epoch number
        train_losses: List of training losses
        val_losses: List of validation losses
        accuracies: List of validation accuracies (if available)
    """
    if not os.path.exists(filename):
        print(f"No checkpoint found at {filename}")
        return 0, [], [], []

    # Load checkpoint
    checkpoint = torch.load(filename)

    # Load model and optimizer states
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

    epoch = checkpoint['epoch']
    train_losses = checkpoint.get('train_losses', [])
    val_losses = checkpoint.get('val_losses', [])
    accuracies = checkpoint.get('accuracies', [])

    print(f"Loaded checkpoint from epoch {epoch}")
    return epoch, train_losses, val_losses, accuracies


def train_self_supervised(model, train_loader, val_loader, device, epochs=20, lr=1e-3,
                          checkpoint_dir='checkpoints', resume=False, checkpoint_freq=5):
    """
    Train the model using self-supervised reconstruction loss with checkpointing.

    Args:
        model: LatentModel
        train_loader: DataLoader for training data
        val_loader: DataLoader for validation data
        device: Device to train on ('cuda' or 'cpu')
        epochs: Number of training epochs
        lr: Learning rate
        checkpoint_dir: Directory to save checkpoints
        resume: Whether to resume from checkpoint
        checkpoint_freq: Frequency (in epochs) to save checkpoints

    Returns:
        Trained model and training history
    """
    model = model.to(device)

    # Set model to only train encoder and decoder
    model.freeze_classifier(True)
    model.freeze_encoder(False)
    model.freeze_decoder(False)

    optimizer = optim.Adam(
        list(model.encoder.parameters()) + list(model.decoder.parameters()),
        lr=lr
    )
    criterion = nn.MSELoss()

    # Initialize history lists
    train_losses = []
    val_losses = []

    # Checkpoint filename
    checkpoint_file = f"{checkpoint_dir}/autoencoder_checkpoint.pth"

    # Resume from checkpoint if requested
    start_epoch = 0
    if resume:
        start_epoch, train_losses, val_losses, _ = load_checkpoint(
            model, optimizer, checkpoint_file
        )

    for epoch in range(start_epoch, epochs):
        # Training phase
        model.train()
        train_loss = 0

        for data, _ in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            data = data.to(device)

            # Forward pass (autoencoder mode)
            reconstructed, _ = model(data, mode='autoencoder')

            # Flatten the input if needed
            if len(data.shape) > 2:
                batch_size = data.size(0)
                data = data.view(batch_size, -1)

            # Calculate loss and backpropagate
            loss = criterion(reconstructed, data)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)
        train_losses.append(train_loss)

        # Validation phase
        model.eval()
        val_loss = 0

        with torch.no_grad():
            for data, _ in val_loader:
                data = data.to(device)

                # Forward pass (autoencoder mode)
                reconstructed, _ = model(data, mode='autoencoder')

                # Flatten the input if needed
                if len(data.shape) > 2:
                    batch_size = data.size(0)
                    data = data.view(batch_size, -1)

                # Calculate loss
                loss = criterion(reconstructed, data)
                val_loss += loss.item()

        val_loss /= len(val_loader)
        val_losses.append(val_loss)

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")

        # Save checkpoint
        if (epoch + 1) % checkpoint_freq == 0 or epoch == epochs - 1:
            save_checkpoint(
                model, optimizer, epoch + 1, train_losses, val_losses,
                filename=checkpoint_file
            )

    # Create and save the plots
    plot_training_curves(train_losses, val_losses, 'Autoencoder Training and Validation Loss',
                         'autoencoder_training.png')

    return model, {'train_losses': train_losses, 'val_losses': val_losses}

def train_classifier_with_frozen_encoder(model, train_loader, val_loader, device, epochs=20, lr=1e-3,
                                        checkpoint_dir='checkpoints', resume=False, checkpoint_freq=5):
    """
    Train the classifier using the frozen encoder with checkpointing.

    Args:
        model: LatentModel with pre-trained encoder
        train_loader: DataLoader for training data
        val_loader: DataLoader for validation data
        device: Device to train on ('cuda' or 'cpu')
        epochs: Number of training epochs
        lr: Learning rate
        checkpoint_dir: Directory to save checkpoints
        resume: Whether to resume from checkpoint
        checkpoint_freq: Frequency (in epochs) to save checkpoints

    Returns:
        Trained model and training history
    """
    model = model.to(device)

    # Freeze encoder, train only the classifier
    model.freeze_encoder(True)
    model.freeze_decoder(True)
    model.freeze_classifier(False)

    optimizer = optim.Adam(model.classifier.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    # Initialize history lists
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    # Checkpoint filename
    checkpoint_file = f"{checkpoint_dir}/classifier_checkpoint.pth"

    # Resume from checkpoint if requested
    start_epoch = 0
    if resume:
        start_epoch, train_losses, val_losses, val_accuracies = load_checkpoint(
            model, optimizer, checkpoint_file
        )
        # Initialize train_accuracies if it's a new list
        if not train_accuracies and val_accuracies:
            train_accuracies = [0] * len(val_accuracies)

    for epoch in range(start_epoch, epochs):
        # Training phase
        model.train()
        train_loss = 0
        correct = 0
        total = 0

        for data, targets in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            data, targets = data.to(device), targets.to(device)

            # Forward pass (classifier mode)
            outputs = model(data, mode='classifier')

            # Calculate loss and backpropagate
            loss = criterion(outputs, targets)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

            # Calculate accuracy
            _, predicted = torch.max(outputs.data, 1)
            total += targets.size(0)
            correct += (predicted == targets).sum().item()

        train_loss /= len(train_loader)
        train_accuracy = 100 * (correct / total)

        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)

        # Validation phase
        model.eval()
        val_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)

                # Forward pass (classifier mode)
                outputs = model(data, mode='classifier')

                # Calculate loss
                loss = criterion(outputs, targets)
                val_loss += loss.item()

                # Calculate accuracy
                _, predicted = torch.max(outputs.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()

        val_loss /= len(val_loader)
        val_accuracy = 100 * correct / total

        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Train Acc: {train_accuracy:.2f}%, "
              f"Val Loss: {val_loss:.6f}, Val Acc: {val_accuracy:.2f}%")

        # Save checkpoint
        if (epoch + 1) % checkpoint_freq == 0 or epoch == epochs - 1:
            save_checkpoint(
                model, optimizer, epoch + 1, train_losses, val_losses, val_accuracies,
                filename=checkpoint_file
            )

    # Create and save the plots
    plot_training_curves(train_losses, val_losses, 'Classifier Training and Validation Loss',
                         'classifier_training_loss.png')
    plot_training_curves(train_accuracies, val_accuracies, 'Classifier Training and Validation Accuracy',
                         'classifier_training_accuracy.png', ylabel='Accuracy (%)')

    return model, {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accuracies': train_accuracies,
        'val_accuracies': val_accuracies
    }

def plot_training_curves(train_values, val_values, title, filename, xlabel='Epoch', ylabel='Loss'):
    """
    Plot training curves and save the figure.

    Args:
        train_values: List of training values (loss or accuracy)
        val_values: List of validation values (loss or accuracy)
        title: Plot title
        filename: Filename to save the plot
        xlabel: X-axis label
        ylabel: Y-axis label
    """
    plt.figure(figsize=(10, 5))
    plt.plot(train_values, label='Training')
    plt.plot(val_values, label='Validation')
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.legend()
    plt.grid(True)
    plt.savefig(filename)
    plt.close()

def visualize_reconstructions(model, test_loader, device, num_examples=10):
    """
    Visualize original images and their reconstructions.

    Args:
        model: LatentModel
        test_loader: DataLoader for test data
        device: Device to use ('cuda' or 'cpu')
        num_examples: Number of examples to visualize
    """
    model.eval()

    # Get some test examples
    dataiter = iter(test_loader)
    images, labels = next(dataiter)
    images = images[:num_examples].to(device)

    # Get reconstructions
    with torch.no_grad():
        reconstructed, _ = model(images, mode='autoencoder')

    # Convert to numpy for plotting
    images = images.cpu().numpy()

    # Reshape reconstructed images
    if len(images.shape) > 2:
        # For image datasets like MNIST or CIFAR
        reconstructed = reconstructed.view(images.shape).cpu().numpy()
    else:
        # For flat data
        reconstructed = reconstructed.cpu().numpy().reshape(images.shape)

    # Plot original and reconstructed images
    plt.figure(figsize=(20, 4))
    for i in range(num_examples):
        # Original
        ax = plt.subplot(2, num_examples, i + 1)
        if images.shape[1] == 1:  # Grayscale (e.g., MNIST)
            plt.imshow(images[i][0], cmap='gray')
        else:  # RGB (e.g., CIFAR)
            plt.imshow(np.transpose(images[i], (1, 2, 0)))
        plt.title(f"Original: {labels[i]}")
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

        # Reconstructed
        ax = plt.subplot(2, num_examples, num_examples + i + 1)
        if images.shape[1] == 1:  # Grayscale
            plt.imshow(reconstructed[i][0], cmap='gray')
        else:  # RGB
            plt.imshow(np.transpose(reconstructed[i], (1, 2, 0)))
        plt.title(f"Reconstructed")
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

    plt.suptitle('Autoencoder Reconstructions', fontsize=16)
    plt.tight_layout()
    plt.savefig('reconstructions.png')
    plt.close()
